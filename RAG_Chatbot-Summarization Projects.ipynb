{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# WELCOME\n","\n","This notebook will guide you through two increasingly significant applications in the realm of Generative AI: RAG (Retrieval Augmented Generation) chatbots and text summarization for big text.\n","\n","Through two distinct projects, you will explore these technologies and enhance your skills. Detailed descriptions of the projects are provided below."],"metadata":{"id":"DxOaSxtJWV1G"}},{"cell_type":"markdown","source":["## Project 1: Building a Chatbot with a PDF Document (RAG)\n","\n","In this project, you will develop a chatbot using a provided PDF document from web page. You will utilize the Langchain framework along with a large language model (LLM) such as GPT or Gemini. The chatbot will leverage the Retrieval Augmented Generation (RAG) technique to comprehend the document's content and respond to user queries effectively.\n","\n","### **Project Steps:**\n","\n","- **1.PDF Document Upload:** Upload the provided PDF document from web page (https://aclanthology.org/N19-1423.pdf) (BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding).\n","\n","- **2.Chunking:** Divide the uploaded PDF document into smaller segments (chunks). This facilitates more efficient information processing by the LLM.\n","\n","- **3.ChromaDB Setup:**\n","  - Save ChromaDB to your Google Drive.\n","\n","  - Retrieve ChromaDB from your Drive to begin using it in your project.\n","\n","  - ChromaDB serves as a vector database to store embedding vectors generated from your document.\n","\n","- **4.Embedding Vectors Creation:**\n","  - Convert the chunked document into embedding vectors. You can use either GPT or Gemini embedding models for this purpose.\n","\n","  - If you choose the Gemini embedding model, set \"task_type\" to \"retrieval_document\" when converting the chunked document.\n","\n","- **5.Chatbot Development:**\n","  - Utilize the **load_qa_chain** function from the Langchain library to build the chatbot.\n","\n","  - This function will interpret user queries, retrieve relevant information from **ChromaDB**, and generate responses accordingly.\n","\n"],"metadata":{"id":"MaCz7nhxKI9R"}},{"cell_type":"markdown","source":["### Install Libraries"],"metadata":{"id":"_eoQWi-uN0dx"}},{"cell_type":"code","source":[],"metadata":{"id":"PCbI4MuNanVu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qOaahY-AancA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Access Google Drive"],"metadata":{"id":"FuLllnCl2yfe"}},{"cell_type":"code","source":[],"metadata":{"id":"uQR06EhDapPP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Entering Your OpenAI or Google Gemini API Key."],"metadata":{"id":"0uR9bJp_0MyF"}},{"cell_type":"code","source":[],"metadata":{"id":"2jwo1SQ2asnZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"90rF1aM1astv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Loading PDF Document"],"metadata":{"id":"OV9rG-0PN8p0"}},{"cell_type":"code","source":[],"metadata":{"id":"5H6eQyYyauxP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"n_kXJZ5Taupv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Document Splitter"],"metadata":{"id":"WLQ1j_JrOF57"}},{"cell_type":"code","source":[],"metadata":{"id":"HHQlclU9awwa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"NaQV6XRwawpf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 1. Creating A Embedding Model\n","### 2. Convert the Each Chunk of The Split Document to Embedding Vectors\n","### 3. Storing of The Embedding Vectors to Vectorstore\n","### 4. Save the Vectorstore to Your Drive"],"metadata":{"id":"4ENim_5MOT9O"}},{"cell_type":"code","source":[],"metadata":{"id":"96nLFF1ja0k_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"VqZ7XBwoa0ee"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Load Vectorstore(index) From Your Drive"],"metadata":{"id":"y2tMqUthPchD"}},{"cell_type":"code","source":[],"metadata":{"id":"5pjKXmO6a3En"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"AXQwX35ha282"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Retrival the First 5 Chunks That Are Most Similar to The User Query from The Document"],"metadata":{"id":"pKA0PgNJQOmj"}},{"cell_type":"code","source":[],"metadata":{"id":"KRH-FWEua5Fn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"80TWdFk6a4-3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Generating an Answer Based on The Similar Chunks"],"metadata":{"id":"-G8R4V7BROkz"}},{"cell_type":"code","source":[],"metadata":{"id":"XNDU0jcma7HB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"aUnTIxSoa6_y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Pipeline For RAG"],"metadata":{"id":"sy4fmzsWLayT"}},{"cell_type":"code","source":[],"metadata":{"id":"_aSt7YgIa9jo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"2PzfTncDa9dO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Project 2: Generating PDF Document Summaries\n","\n","In this project, you will explore various methods for creating summaries from the provided PDF document. You will experiment with different chaining functions offered by the Langchain library to achieve this.\n","\n","### **Project Steps:**\n","- **1.PDF Document Upload and Chunking:** As in the first project, upload the PDF document and divide it into smaller chunks. Consider splitting it by half-page or page.\n","\n","- **2.Summarization Techniques:**\n","\n","  - **Summary of the First 5 Pages (Stuff Chain):** Utilize the load_summarize_chain function with the parameter chain_type=\"stuff\" to generate a concise summary of the first 5 pages of the PDF document.\n","\n","  - **Short Summary of the Entire Document (Map Reduce Chain):** Employ chain_type=\"map_reduce\" and refine parameters to create a brief summary of the entire document. This method generates individual summaries for each chunk and then combines them into a final summary.\n","\n","  - **Detailed Summary with Bullet Points (Map Reduce Chain):** Use chain_type=\"map_reduce\" to generate a detailed summary with at least 1000 tokens. Provide the LLM with the prompt \"Summarize with 1000 tokens\" and set the max_token parameter to a value greater than 1000. Add a title to the summary and present key points using bullet points.\n","\n","### Important Notes:\n","\n","- Models like GPT-4o and Gemini Pro models might excel in generating summaries based on token count. Consider prioritizing these models.\n","\n","- For comprehensive information on Langchain and LLMs, refer to their respective documentation.\n","Best of luck!"],"metadata":{"id":"H9GmKlL2NRff"}},{"cell_type":"markdown","source":["### Install Libraries"],"metadata":{"id":"WhjLe0IqRnl4"}},{"cell_type":"code","source":[],"metadata":{"id":"ZXdV8CcqbFrW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"rcFsXQwCbFkm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Loading PDF Document"],"metadata":{"id":"yqImlx_IRqQS"}},{"cell_type":"code","source":[],"metadata":{"id":"CCkT3msfbH_n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"5a_FpBOcbHzP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Summarizing the First 5 Pages of The Document With Chain_Type of The 'stuff'"],"metadata":{"id":"LuyT0IoWR4n8"}},{"cell_type":"code","source":[],"metadata":{"id":"O3yAnW3PbKIX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8wopgGPibKA3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Document Splitter"],"metadata":{"id":"JvrLsoivTulb"}},{"cell_type":"code","source":[],"metadata":{"id":"5j9NMbSCbMyf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"53mpwb7KbMrf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Make A Brief Summary of The Entire Document With Chain_Types of \"map_reduce\" and \"refine\""],"metadata":{"id":"3zlVe2iISX0Q"}},{"cell_type":"code","source":[],"metadata":{"id":"t6wPW3OFbOcJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8NpJYGxRbOVC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Generate A Detailed Summary of The Entire Document With At Least 1000 Tokens. Also, Add A Title To The Summary And Present Key Points Using Bullet Points With Chain_Type of \"map_reduce\"."],"metadata":{"id":"9zZxse-ZUV3S"}},{"cell_type":"code","source":[],"metadata":{"id":"lpuiEedJbQME"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"OdFF9bOAbQEo"},"execution_count":null,"outputs":[]}]}